Gauss transform is one of several discrete spatial transforms of the form 
%
\beq F(x_j) = \sum_{k=1}^N \kernel f(y_k) \quad \text{at} \quad \{ x_j \, | \, j = 1,...,M \}.  \label{gt} \eeq
%
We refer to the points $ x_j, y_k \in \mathbb{R}^3 $ as the targets and sources respectively. The kernel $G_\delta$ is a smooth exponentially decaying function in both the physical and Fourier domains. We shall call such kernels as {\em Gaussian-type}. The parameter $\delta$ controls how rapidly the kernel decays.  In the Gauss transform case, $\kernel = e^{-\frac{\norm{x_j - y_k}^2}{\delta}}$. 

Discrete sums of the form (\ref{gt}) are encountered in a variety of disciplines including computational physics,
 machine learning, computational finance and computer graphics \cite{strain94adap, elgammal03, broadie03, kim05, veerapaneni08}. The 
 motivation for the present work comes from {\em potential theory} \cite{kress99}, which is used to solve linear parabolic partial 
 differential equations (PDEs). Several advantages characterize potential theoretic approaches including reduction in dimensionality, exact 
 satisfaction of the far-field conditions, and high-order space-time discretizations. A computational bottle-neck in such approaches is the 
 need to compute sums of the form (\ref{gt}). For example, high-order methods for the heat potentials require evaluating the convolutions \cite{li09, skv09}
% 
\beq F(x) = \int_\Omega \norm{x - y}^{2n} e^{-\frac{\norm{x - y}^2}{\delta}} f(y) \, d\Omega \label{heat} \eeq
% 
where $\Omega$ is the the domain and $n$ is a positive integer. Nystr\"{o}m method based on Gaussian quadrature for (\ref{heat}) gives rise to discrete sums of the form (\ref{gt}) because the kernel in (\ref{heat}) decays in both physical and Fourier domain \cite{fggt}. More examples of Gaussian-type kernels can be found in \cite{victor03}. If the kernel decays rapidly, one can simply truncate the sum to a few neighboring sources at each target. However, in many applications including heat potentials, this is not the case and computing these sums directly takes $\bigO(NM)$ time. 

{\em Related work.} Because of their fundamental importance, fast schemes for (\ref{gt}) received significant attention in the recent past. Starting from the earlier work of Greengard and Strain \cite{fgt}, several sequential algorithms \cite{greengard98, sun02, duraiswami03, tausch09, fggt} have been proposed to reduce the cost to an optimal $\bigO(N+M)$. Recently, some effort in parallelizing has been made in \cite{rio09} in the context of radial basis function (RBF) interpolation using Gaussians. But their scheme is based on truncating the sum locally and does not generalize. To our knowledge, there have been no parallel implementations to date that compute (\ref{gt}) in all parameter ranges. 

{\em Contributions.} The main contributions of this work are summarized below.
\begin{itemize} 
%
\item We present the first ever parallel implementation of the fast gauss transform. 
We incorporate the accelerations introduced in \cite{fggt} for tensor product grids. 
Thereby, the complexity constants in our scheme scale linearly with the number of dimensions 
as opposed to exponential growth. 
%
\item We present a novel scheme for the translation of plane wave expansions; this is one
of the steps in the sequential fast gauss transform algorithm. Our new scheme reduces the 
 storage costs required for this step compared to previous implementations, especially for highly
non-uniform point distributions.
%
\item We extend our schemes to nonuniform distributions. \ul{OCTREES}.

\item The cost FGT grows for smaller values of $\delta$. In the nonuniform case, 
We present a scheme that scales well in all ranges of the parameters. It is an extension of the tree-splitting scheme 
proposed in \cite{veerapaneni08} for computing continuous Gauss transforms. 
%
\end{itemize}

The rest of the paper is organized as follows. In Section \ref{sc:fgt}, we give a high-level description of FGT for uniform point distributions and discuss its parallelization. We introduce a novel translation scheme in Section \ref{sc:sweep}. This scheme is slightly more expensive compared to the {\em sweeping algorithm} introduced in \cite{greengard98} but it 
significantly improves the storage cost for nonuniform distributions. We also discuss its parallel implementation. In Section 
\ref{sc:nonuniform}, we present our octree-based sequential and parallel algorithms for nonuniform distributions. Finally, in 
Section \ref{sc:results}, we  present scalability results of our algorithm using a variety of test cases. 
In the rest of the paper, we stick to the case where $G_\delta$ is a Gaussian. This is purely for ease of exposition, all the concepts 
are valid in the general case too unless stated otherwise. 
