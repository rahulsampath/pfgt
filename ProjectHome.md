We present fast adaptive parallel algorithms to compute the sum of N Gaussians at N points. Direct sequential computation of this sum would take O(N^2) time. The parallel time complexity estimates for our algorithms are O(N/n\_p) for uniform point distributions and O( (N/n\_p) log (N/n\_p) + n\_p log n\_p ) for non-uniform distributions using n\_p CPUs. We incorporate a plane-wave representation of the Gaussian kernel which permits "diagonal translation". We use parallel octrees and a new scheme for translating the plane-waves to efficiently handle non-uniform distributions. Computing the transform to six-digit accuracy at 120 billion points took approximately 140 seconds using 4096 cores on the Jaguar supercomputer. Our implementation is "kernel-independent" and can handle other "Gaussian-type" kernels even when explicit analytic expression for the kernel is not known. These algorithms form a new class of core computational machinery for solving parabolic PDEs on massively parallel architectures.

The paper describing this work can be found here: http://sc10.supercomputing.org/schedule/event_detail.php?evid=pap294